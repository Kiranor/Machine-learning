{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка на форму для заполнения ответов домашней работы](https://forms.gle/4LKA92qe7y9ushb79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "### Структуры данных Pandas\n",
    "#### Series\n",
    "- Series - одномерная структура данных, которая может хранить в себе данные одного типа. Series напоминает словарь, так как позволяет получать элементы по индексу, который может быть не только целочисленного типа. Свойства Series:\n",
    "    - Series.index - индексы элементов\n",
    "    - Series.values - значения элементов\n",
    "    \n",
    "#### DataFrame\n",
    "- DataFrame - двумерная структура данных, которая может хранить в себе данные разных типов. По сути, DataFrame это матрица, где столбцами являются признаки, а строками объекты. Каждая колонка DataFrame имеет тип Series. DataFrame имеет много методов и свойств для аналитики, получения срезов и преобразования данных. Вот некоторые из них:\n",
    "    - DataFrame.info() - получение общей информации по датафрейму\n",
    "    - DataFrame.dtypes - типы колонок\n",
    "    - DataFrame.columns - имена колонок\n",
    "    \n",
    "Для того, чтобы считать данные из файла в DataFrame, в библиотеке предусмотрено множество функций. Большинство из них начинаются с префикса 'read' - например:\n",
    "   - pandas.read_csv - читает данные из файла с расширением .csv\n",
    "   - pandas.read_excel - читает данные из файла .xlsx\n",
    "Эти методы имеют много параметров, начиная от имени файла и заканчивая кодировкой и разделителем.\n",
    "\n",
    "Более подробно с методами DataFrame можно ознакомиться в документации к Pandas, ссылка на которую приводится в разделе \"Полезные ссылки\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Далее мы будем рассматривать датасет с реальными данными из нефтяной отрасли: дебит жидкости после ГТМ (геолого-технического мероприятия)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание смысла признаков\n",
    "Признак | Описание\n",
    "--------| -------------\n",
    "Dnytr | диаметр трубы\n",
    "H_din |   Динамический уровень\n",
    "Q_OIS |   Дебит жидкости\n",
    "NomMoschn |\tНоминальная мощность\n",
    "Hperf |\tГлубина перфораций\n",
    "NomNapor\t| Номинальный напор\n",
    "Water_cut |\tОбводненность\n",
    "NomPodacha\t| Номинальная подача\n",
    "Dnkt |\tДиаметр НКТ\n",
    "H_sp\t| Глубина спуска\n",
    "P_plst\t| Пластовое давление\n",
    "Hvd\t| Глубина верхних дыр перфораций\n",
    "Extend_Hvd\t| Удлинение верхних дыр перфораций\n",
    "PlNeft |\tПлотность нефти\n",
    "VyazkNeft\t| Вязкость нефти\n",
    "SumTolshin\t| Сумма нефтенасыщенных толщин\n",
    "P_zatr\t| Затрубное давление\n",
    "PlVody |\tПлотность воды\n",
    "Pnas\t| Давление насыщения\n",
    "Inject_0,1,2,3\t| Приемистость ближайших нагнетательных скважин\n",
    "BHP\t| Забойное давление\n",
    "State\t| Состояние скважины (работает, не работает)\n",
    "IDN_type |\tТип ГТМ (ИДН или ППР)\n",
    "NalichSep |\tНаличие сепаратора\n",
    "Formation_lbl |\tМетка пласта\n",
    "state_age\t| Возраст состояние\n",
    "Date |\tДата\n",
    "Start_date\t| Дата начала ГТМ\n",
    "Well_ID|\tID скважины\n",
    "id\tID| ГТМ\n",
    "VNR|\tПризнак выхода на режим\n",
    "Date_VNR|\tДата выхода на режим\n",
    "GTM_type_lbl|\tМетка типа ГТМ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание задачи\n",
    "На основе предоставленных данных построить модель прогнозирования дебита жидкости (признак ‘Q_OIS’) после геолого-технического мероприятия (ГТМ) – итенсификация добычи нефти (ИДН). Прогноз необходимо сделать на дату выхода скажины на режим (дата ВНР). Точка прогноза однозначно задается бинарным признаком ‘VNR’ (точка прогноза – VNR=1).\n",
    "\n",
    "Каждому событию ИДН предшествует своя история, однозначно определяемая признаком ‘id’. В тренировочном датасете ‘contest_train_df.csv’ для каждого факта ИДН (признак ‘id’) известно значение дебита жидкости ‘Q_OIS’ на дату ВНР (VNR=1).\n",
    "\n",
    "Также в качестве дополнительной информации дана таблица со всеми типами ГТМ, проведенными на исследуемых скважинах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# чтение данных из файла с расширением .csv\n",
    "df = pd.read_csv('contest_train_df.csv')\n",
    "# общая информация о датафрейме\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Имя первого признака\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обращение к колонке DataFrame по имени\n",
    "# слева - индекс, справа - значение\n",
    "# возвращается тип Series\n",
    "df['Dnkt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение элемента Series по индексу\n",
    "df['H_sp'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 1. Какое значение лежит в колонке Formation_lbl по индексу 297?\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Статистика по DataFrame и Series\n",
    "Ещё несколько полезных функций для получения информации о данных в датафрейме:\n",
    "\n",
    "- DataFrame.describe() - получение описательной статистики\n",
    "- Series().value_counts - подсчёт поличества вхождений значений в Series\n",
    "- Series.unique(), Series.nunique() - множество уникальных значений в Series и количество уникальных\n",
    "- DataFrame.head() - первые несколько записей DataFrame\n",
    "- Series.max(), Series.min() - максимальное и минимальное значения\n",
    "- Series.mean(), Series.median() - среднее и медианное значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала хочется просто посмотреть на данные\n",
    "# выведем первые 10 записей датасета\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# размер таблицы, возвращается кортеж (количество записей, количество столбцов)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как оценить данные в общем?\n",
    "# полученим статистику по датафрейму\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если хочется посмотреть только на часть выбранных признаков\n",
    "# стоит выделить их и заново сделать describe\n",
    "\n",
    "df[['Q_OIS', # этот признак интересует, потому что он целевой\n",
    "   'VNR',   # этот признак является важным идентифкатором\n",
    "    'Water_cut' # это признак, связанный с жидкостью\n",
    "   ]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество уникальных значений в признаке\n",
    "df['VNR'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# похоже, признак VNR бинарный - у него всего два уникальных значения\n",
    "# убедимся, что эти два значения - 1 и 0\n",
    "df['VNR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 2. Сколько в датасете признаков, у которых всего 2 уникальных значения?\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 3. Сколько уникальных значений в признаке Water_cut?\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 4. Совпадает ли медиана и среднее у признака Extend_Hvd?\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 5. Какое максимальное значение у признака NomPodacha?\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Пропуски\n",
    "Пропуски - отсутствующие значения в данных. С пропусками в данных можно бороться несколькими способами: заполнять их, или удалять объекты с пропусками. Если пропусков немного, то удаление объектов с пропусками может быть приемлимо, однако во многих случаях пропуски предпочтительнее заполнить, чтобы не потерять нужную информацию.\n",
    "Pandas предоставляет несколько методов для работы с пропусками:\n",
    "- Series.isna() - возвращает True для каждого пропуска\n",
    "- Series.dropna() - удаляет все пропуски\n",
    "- Series.fillna() - заполняет пропуски\n",
    "\n",
    "##### Дубликаты\n",
    "Дубликаты - повторяющиеся значения в данных. Дубликаты вредны: они создают неверное представление о данных (распределениях) и часто являются причиной ошибок (в данных и в процессе их обработки).\n",
    "Для работы с дубликатами в Pandas:\n",
    "- DataFrame.drop_duplicates() - удаляет все дублирующиеся значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# так как признак VNR оказался бинарным, преобразуем его к нужному типу\n",
    "df['VNR'] = df['VNR'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VNR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в выводе первых строк датасета было видно очень много пропусков (NaN)\n",
    "# а сколько их точно?\n",
    "# количество пропусков по всем признакам (колонкам)\n",
    "# df.count() - количество заполненных по признакам (колонкам)\n",
    "for col in df.columns:\n",
    "    print('Признак = {:<13}: количество пропусков = {}'.format(col, df[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим, сколько останется данных\n",
    "# если просто убрать все объекты (строки) в которых есть хотя бы один пропуск:\n",
    "df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если убрать все объекты с пропусками, то мы теряем очень много данных\n",
    "# проверим, есть ли строки, в которых пропущены воообще все значения?\n",
    "df.dropna(how='all').shape[0] != df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# абсолютно пустых строк в датасете нет, значит просто убрать пропуски мы не можем\n",
    "# лучше всего будет заполнить пропуски средним, но так как датасет довольно большой,\n",
    "# сделаем это после группировки и создания агрегатов\n",
    "# чтобы узнать, сколько всего будет уникальных скважин (а значит и строк в сгруппированном датасете) \n",
    "# вызовем метод nunique для признака Well_ID\n",
    "df['Well_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 6. Каков процент (%) пропусков в колонке NomNapor? Округлите ответ до двух знаков после запятой.\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 7. Во сколько раз уменьшится размер датафрейма если сделать drop_duplicates по колонкам 'Dnkt','Dnytr'?\n",
    "# Округлите ответ до целых.\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 8. Изменится ли среднее значение признака NomNapor если заполнить в нём пропуски значением 0?\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Агрегация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Группировка и агрегация\n",
    "В pandas для группировки данных реализован метод **DataFrame.groupby()**. Он возвращает сгруппированный по указанному признаку датафрейм, к которому можно применять различные функции-агрегаты: например, выделение суммы для группы, подсчёт внутри группы более сложных агрегатов.\n",
    "\n",
    "#### Использование lambda и apply\n",
    "В случае потребности в нестандартных агрегатах можно воспользоваться **lambda-функцией** - для датафрейма она будет принимать Series, а для Series ячейку массива. Применить lambda-функцию к датафрейму можно через **apply** - этот метод принимает на вход функцию и применяет её ко всем элементам датафрейма (или Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим агрегаты по признакам state_age и Water_cut\n",
    "df.aggregate({'state_age': ['max', 'mean'],\n",
    "              'Water_cut': ['max', 'min']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгруппируем датафрейм по признаку Well_ID\n",
    "df_grouped = df.groupby('Well_ID')\n",
    "# выведем результат\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь получим агрегаты из первого пункта по сгруппированному датафрему\n",
    "df_grouped.aggregate({'state_age': ['max', 'mean'],\n",
    "                      'Water_cut': ['max', 'min']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравним округлённые значения средних и медианы по сгруппированному датафрейму\n",
    "df_grouped.aggregate({'state_age':lambda x: round(np.median(x))==round(np.mean(x))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим, какова разница между максимумом и минимумом по признаку Water_cut\n",
    "df_grouped['Water_cut'].apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 9. У скольки объектов при группировке по Well_ID среднее и медиана по признаку state_age не равны?\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сводные таблицы и корреляция\n",
    "#### Сводные таблицы.\n",
    "В pandas для построения сводных таблиц реализован метод pivot_table() - он принимает признаки и функции, которые нужно применить к этим признака. Кроме прочего, ему надо передать колонку, которая будет являться идентификатором в результирующей сводной таблице.\n",
    "\n",
    "#### Корреляция\n",
    "Корреляция - мера линейной (монотонной) зависимости. В pandas расчёт коэффициента корреляции реализован в методе corr(). По умолчанию рассчитывается коэффициент корреляции Пирсона, он может принимать значения от -1 до 1, где абсолютное значение отвечает за силу взаимосвязи, а знак - за её направление."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(values='Water_cut',\n",
    "               index='Well_ID',\n",
    "               aggfunc=['mean','max','min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(values=['Dnytr','Q_OIS'],\n",
    "               index='VNR',\n",
    "               aggfunc=['std','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = df_grouped.aggregate({'Q_OIS': ['max', 'mean'],\n",
    "                      'Water_cut': ['max', 'mean']})\n",
    "agg_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вопрос 10. С помощью функции aggregate найдите максимум, минимум, медиану по признакам\n",
    "#            Q_OIS, Water_cut, NomMoschn, P_plst для каждой скважины (по датафрейму, сгруппированному по Well_ID).\n",
    "#            Посчитайте коэффициент корреляции Пирсона для этих агрегатов.\n",
    "#            Есть ли среди этих агрегатов такие, коэффициент корреляции у которых больше 0.8?\n",
    "\n",
    "# код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенная визуализация\n",
    "\n",
    "Для визуализации датафрейм имеет метод **plot()**. Главные параметры, которые он принимает, это названия признаков и вид графика, который нужно по этим признакам отрисовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1000).plot(y='Water_cut',kind='kde',figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1000).plot(y='Water_cut',kind='hist',figsize=(5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv('filename.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_excel('filename.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полезные ссылки:\n",
    "- [Документация Pandas ](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "- [Средние величины](https://ru.wikipedia.org/wiki/%D0%9A%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D1%8F:%D0%A1%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D0%B5_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D1%8B)\n",
    "- [Видео-туториалы Pandas на английском](https://www.youtube.com/watch?v=CmorAWRsCAw#action=share)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительные материалы - теория и практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Объединение датафреймов\n",
    "Если данные берутся из нескольких источников, которые имеют общие идентификаторы, то объединить их можно методом **merge()**. Этот метод довольно гибкий - можно указывать имена колонок для объединения в каждом из датафремов, указывать тип объединения и др.\n",
    "\n",
    "Тип объединения обычно выбирают в зависимости от конечной цели: если мы хотим сохранить обсолютно все объекты из обоих источников, даже при условии, что они будут почти не заполнены, можно выбрать тип \"*outer*\" .\n",
    "Если у нас есть один наиболее доверенный источник, в качестве данных которого мы уверены, то можно присодинять данные из других источников с указанием типа \"*left*\" - в этом случае объекты, которых не будет в первом источнике, также не попадут и в конечный датафрейм.\n",
    "\n",
    "Типу объединения соответствуют два понятия из теории множеста: **a.merge(b, how=\"inner\")** - *пересечение множеств* a и b,\n",
    "**a.merge(b, how=\"outer\")** - *объединение множеств* a и b.\n",
    "\n",
    "Ниже приведены несколько примеров объединения с помощью метода **merge()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим два игрушечных датасета с разным набром объектов и разными колонками, чтобы увидеть\n",
    "# как работают различные типы объединения\n",
    "a = pd.DataFrame({'UID':[0,1,2,3,4,5],\n",
    "                  'Должность':['Инженер','Инженер','Заместитель директора', 'Менеджер','Главный инженер','Менеджер'],\n",
    "                  'Оклад (тыс.руб)':[35, 38, 95, 35, 58, 32]})\n",
    "\n",
    "b = pd.DataFrame({'UID':[0,1,2,3,4],\n",
    "                  'Возраст':[23,32,40,25,50],\n",
    "                  'Образование':['Среднее специальное','Высшее','Высшее','Среднее специальное','К.т.н']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.merge(b, on='UID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.merge(b, on='UID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предположим, что мы хотим посмотреть размеры окладов в разрезе возраста и образования\n",
    "# в этом случае outer тип для нас бесполезен - так как не принёсёт в данные нужной информации\n",
    "df = a.merge(b, on='UID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на средние оклады людей до 35 (включительно) и после 35\n",
    "round(df[df['Возраст'] <= 30]['Оклад (тыс.руб)'].mean(),2),round(df[df['Возраст'] > 30]['Оклад (тыс.руб)'].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь сгруппируем наш датафрейм по типу образования и посмотрим на статистику по окладу\n",
    "df.groupby('Образование')['Оклад (тыс.руб)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь предположим, что нам дали дополнительные данные по сотрудникам из филиалов компании\n",
    "# мы должны присоединить их к нашему датасету и рассчитать интересующие показатели заново\n",
    "a = pd.DataFrame({'UID':[101, 200, 202, 408, 501],\n",
    "                  'Должность':['Инженер','Менеджер','Старший инженер','Инженер','Оператор поддержки'],\n",
    "                  'Оклад (тыс.руб)':[38, 27, 45, 35, 20]})\n",
    "\n",
    "b = pd.DataFrame({'UID':[101, 200, 202, 408, 501],\n",
    "                  'Возраст':[37, 38, 45, 28, 21],\n",
    "                  'Образование':['Высшее','Высшее','Высшее','Среднее специальное','Среднее']})\n",
    "\n",
    "df_add = a.merge(b, on='UID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединим датафремы\n",
    "df = pd.concat([df, df_add]) # метод concat принимает список из датафреймов, у которых должны быть одинаковые колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df[df['Возраст'] <= 30]['Оклад (тыс.руб)'].mean(),2),round(df[df['Возраст'] > 30]['Оклад (тыс.руб)'].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Образование')['Оклад (тыс.руб)'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оконные функции.\n",
    "Для работы с рапсределёнными во времени данных в pandas существуют оконные функции - они позволяют вычислить агрегаты в рамках небольших временных периодов, так называемых \"окон\", которые можно сдвигать на заданный шаг для повторения рассчётов.\n",
    "В pandas реализовано несколько методов для работы с распределёнными во времени данными:\n",
    "- pandas.rolling() - позволяет произвести оконные вычисления с любой произвольной функцией в рамках заданного окна\n",
    "- pandas.expanding() - позвояет произвести куммулятивные вычисления с любой произвольной функцией для заданного размера окна\n",
    "- pandas.ewm() - позволяет \"сгладить\" данные, подробное описание можно прочесть в документации к pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# представим, что теперь для каждого сотрудника из предыдущего пункта мы решили проанализировать его предыдущую\n",
    "# трудовую деятельность : длительность работы на каждом месте, рост дохода\n",
    "a = pd.DataFrame({'UID':[1, 1, 2, 2, 2, 2, 408, 408, 501],\n",
    "                 'Company_ID':[100, 304, 202, 35, 78, 23, 90, 23, 10],\n",
    "                 'Дата начала работы':['2000-09-01',\n",
    "                                       '2005-12-15',\n",
    "                                       '2003-05-07',\n",
    "                                       '2006-08-02',\n",
    "                                       '2011-10-07',\n",
    "                                       '2017-11-15',\n",
    "                                       '2013-02-02',\n",
    "                                       '2016-09-25',\n",
    "                                       '2018-07-30'\n",
    "                                      ],\n",
    "                 'Дата окончания работы':['2005-11-04',\n",
    "                                          '2015-03-03',\n",
    "                                          '2006-07-24',\n",
    "                                           '2011-10-01',\n",
    "                                           '2016-10-20',\n",
    "                                           '2019-11-08',\n",
    "                                          '2016-06-04',\n",
    "                                          '2018-09-20',\n",
    "                                          '2019-05-14'],\n",
    "                 'Оклад (тыс.руб)':[26, 35, 30, 48, 54, 79, 21, 32, 17]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведём даты к нужному типу, чтобы они корректно отобразились на графике\n",
    "a['Дата начала работы'] = pd.to_datetime(a['Дата начала работы'])\n",
    "a['Дата окончания работы'] = pd.to_datetime(a['Дата окончания работы'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисуем, как менялся оклад работника с UID=2 по годам\n",
    "a[a['UID'] == 2].plot(x='Дата начала работы',y='Оклад (тыс.руб)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгладим наш график для работника с UID=2\n",
    "# попробуйте поменять параметр alpha, чтобы увидеть, как в зависимости от него меняется график\n",
    "a_tmp = a[a['UID'] == 2].ewm(alpha=0.5).mean()\n",
    "a_tmp[['Оклад (тыс.руб)']].merge(a['Дата начала работы'], left_index=True, right_index=True).plot(x='Дата начала работы',y='Оклад (тыс.руб)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгруппируем работников по UID, посмотрим среднее на двух последних местах работы по окладу\n",
    "a_grouped = a.groupby('UID')\n",
    "a_grouped['Оклад (тыс.руб)'].rolling(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Самостоятельная работа:\n",
    "# 1) Попробуйте сгруппировать данные по образованию и должности.\n",
    "# Какая категория людей получает наибольший, а какая наименьший доход?\n",
    "# 2) Закодируйте признак образование по принципу \"выше уровень образования - больше цифра\"\n",
    "# Каково значение коэффициента корреляции Пирсона между уровнем образования и окладом, каков его знак?\n",
    "# (на самом деле, коэффициент корреляции Пирсона здесь не очень подходит -\n",
    "# об этом будет рассказано в следующих лекциях курса)\n",
    "\n",
    "# код тут"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}