{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "#import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ".. _breast_cancer_dataset:\n\nBreast cancer wisconsin (diagnostic) dataset\n--------------------------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 569\n\n    :Number of Attributes: 30 numeric, predictive attributes and the class\n\n    :Attribute Information:\n        - radius (mean of distances from center to points on the perimeter)\n        - texture (standard deviation of gray-scale values)\n        - perimeter\n        - area\n        - smoothness (local variation in radius lengths)\n        - compactness (perimeter^2 / area - 1.0)\n        - concavity (severity of concave portions of the contour)\n        - concave points (number of concave portions of the contour)\n        - symmetry \n        - fractal dimension (\"coastline approximation\" - 1)\n\n        The mean, standard error, and \"worst\" or largest (mean of the three\n        largest values) of these features were computed for each image,\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n        13 is Radius SE, field 23 is Worst Radius.\n\n        - class:\n                - WDBC-Malignant\n                - WDBC-Benign\n\n    :Summary Statistics:\n\n    ===================================== ====== ======\n                                           Min    Max\n    ===================================== ====== ======\n    radius (mean):                        6.981  28.11\n    texture (mean):                       9.71   39.28\n    perimeter (mean):                     43.79  188.5\n    area (mean):                          143.5  2501.0\n    smoothness (mean):                    0.053  0.163\n    compactness (mean):                   0.019  0.345\n    concavity (mean):                     0.0    0.427\n    concave points (mean):                0.0    0.201\n    symmetry (mean):                      0.106  0.304\n    fractal dimension (mean):             0.05   0.097\n    radius (standard error):              0.112  2.873\n    texture (standard error):             0.36   4.885\n    perimeter (standard error):           0.757  21.98\n    area (standard error):                6.802  542.2\n    smoothness (standard error):          0.002  0.031\n    compactness (standard error):         0.002  0.135\n    concavity (standard error):           0.0    0.396\n    concave points (standard error):      0.0    0.053\n    symmetry (standard error):            0.008  0.079\n    fractal dimension (standard error):   0.001  0.03\n    radius (worst):                       7.93   36.04\n    texture (worst):                      12.02  49.54\n    perimeter (worst):                    50.41  251.2\n    area (worst):                         185.2  4254.0\n    smoothness (worst):                   0.071  0.223\n    compactness (worst):                  0.027  1.058\n    concavity (worst):                    0.0    1.252\n    concave points (worst):               0.0    0.291\n    symmetry (worst):                     0.156  0.664\n    fractal dimension (worst):            0.055  0.208\n    ===================================== ====== ======\n\n    :Missing Attribute Values: None\n\n    :Class Distribution: 212 - Malignant, 357 - Benign\n\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n\n    :Donor: Nick Street\n\n    :Date: November, 1995\n\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\nhttps://goo.gl/U2Uwz2\n\nFeatures are computed from a digitized image of a fine needle\naspirate (FNA) of a breast mass.  They describe\ncharacteristics of the cell nuclei present in the image.\n\nSeparating plane described above was obtained using\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\nConstruction Via Linear Programming.\" Proceedings of the 4th\nMidwest Artificial Intelligence and Cognitive Science Society,\npp. 97-101, 1992], a classification method which uses linear\nprogramming to construct a decision tree.  Relevant features\nwere selected using an exhaustive search in the space of 1-4\nfeatures and 1-3 separating planes.\n\nThe actual linear program used to obtain the separating plane\nin the 3-dimensional space is that described in:\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\nProgramming Discrimination of Two Linearly Inseparable Sets\",\nOptimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\n\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\n.. topic:: References\n\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n     San Jose, CA, 1993.\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n     July-August 1995.\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n     163-171.\n"
    }
   ],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "data['target'] = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.drop('target', axis=1), data[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.9906759906759908\n"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "model = LogisticRegressionCV(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.n_iter = 300\n",
    "        self.lambda_ = 0.1\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = X.copy()\n",
    "        X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "        self.w = np.random.randn(X.shape[1], 1)\n",
    "        #print(self.w.T)\n",
    "        #print(self.w.shape)\n",
    "        print(X.shape)\n",
    "        for it in range(self.n_iter):\n",
    "            y_pred = self.predict(X)\n",
    "            grad = X.T @(y * (1 - y_pred) + (1 - y) * y_pred) / len(X)\n",
    "            #grad = X.T @ (y_pred - y) / len(X)\n",
    "            self.w = self.w - self.lambda_ * grad\n",
    "            #print(self.w)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        z = X @ self.w\n",
    "        return self.sigmoid(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(381, 31)\n(381, 30) (31, 1) asd\n"
    }
   ],
   "source": [
    "lr = MyLogisticRegression()\n",
    "lr.fit(X_train, y_train.values)\n",
    "print(X_train.shape, lr.w.shape, \"asd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((31, 1), (381, 30))"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.w.shape,X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[-47683132.55639368]\n [ -9668144.04674911]\n [-11426993.461706  ]\n [-23061201.66084594]\n [-11345776.04641483]\n [-13075449.02861086]\n [-29486230.94869654]\n [-15607711.74320944]\n [-27003722.37060621]\n [-29907494.60835598]\n [-13113312.78355277]\n [-14790804.40383798]\n [-23774584.34891165]\n [ -5504677.86411197]\n [ -6997430.95437616]\n [ -9747525.08569672]\n [-11799411.80172743]\n [-10368360.22877039]\n [-55903318.99129104]\n [-17197781.06966631]\n [-26156417.99157029]\n [-30969440.22195913]\n [-21385119.30260138]\n [ -8481324.23617788]\n [-15050208.66173423]\n [-12018757.74642284]\n [-19899529.08994845]\n [-11391850.46197907]\n [ -9031814.06456332]\n [-48723480.10016793]\n [-12343021.12820831]\n [-13419339.18113793]\n [ -9250159.56457245]\n [ -5731503.35108657]\n [-29796570.35845715]\n [-11065465.77730766]\n [-17172466.90575344]\n [-24402307.7632597 ]\n [ -7055983.5213661 ]\n [-11920494.99866407]\n [-14283056.01231953]\n [-11676725.49756278]\n [ -8417594.74885178]\n [ -9064376.35700438]\n [-27111825.04585406]\n [-12988969.66470838]\n [ -8884523.49813008]\n [-27900394.99522394]\n [-31754038.33130176]\n [-10751931.31312448]\n [-35065853.29934125]\n [ -6274517.05376422]\n [-11617902.78051138]\n [-25031183.83229363]\n [-29644659.95878972]\n [-13262907.65964257]\n [-33451451.17045106]\n [ -6116345.85559201]\n [-16389886.4562374 ]\n [-38154268.47871237]\n [-12037613.16464613]\n [-16825984.48218681]\n [-12391171.39421916]\n [-17252018.53010277]\n [-10189784.30981824]\n [-13981051.35037931]\n [ -7856820.40500354]\n [-10299585.78305668]\n [-21715077.56311379]\n [-14546109.61400835]\n [ -6841563.41503829]\n [ -8996554.59910567]\n [-16972167.31624795]\n [-14720446.85930729]\n [ -7832221.75226838]\n [ -9719178.09378781]\n [-15047667.74404458]\n [-10280739.26922046]\n [-20831980.85756721]\n [ -5916907.01033633]\n [-13055249.8462372 ]\n [-16030733.93076023]\n [ -9979240.45553952]\n [-16806057.4725709 ]\n [-11963627.80504031]\n [-29903185.89536219]\n [-12889170.73282828]\n [-15342501.5048617 ]\n [ -5673832.01755359]\n [-12837386.6964618 ]\n [-18918054.25663291]\n [-21608762.5538431 ]\n [-17395343.84076719]\n [ -8747558.79626378]\n [-30078547.71227056]\n [ -6974230.71642653]\n [-11302652.27677339]\n [-30679596.32597459]\n [-39029074.1252635 ]\n [ -9226920.52032652]\n [-11176970.35802623]\n [-10562432.84318774]\n [ -4754739.57854314]\n [-17873096.08797186]\n [-11199971.00210859]\n [ -4802433.94121374]\n [-10355443.9746571 ]\n [ -5357699.94732221]\n [-13535836.92865031]\n [-20644301.86702272]\n [-22097374.67855898]\n [-39887691.65043255]\n [-19703827.9511778 ]\n [-11179779.76451139]\n [-13701516.75969827]\n [-26782255.07083315]\n [ -8869054.96148604]\n [-13445652.840437  ]\n [-13210268.13846122]\n [ -9116465.17209689]\n [-11174179.99021536]\n [ -7328591.15625477]\n [-22751219.35579429]\n [ -9027139.30850559]\n [ -9673445.73848769]\n [-10667051.83938359]\n [-26272271.69446585]\n [-12489132.10360779]\n [-24914425.66969968]\n [-14753650.17507042]\n [-23146770.86028686]\n [-24047614.7438003 ]\n [ -8342064.27480885]\n [-13315996.26778532]\n [-12210789.94933785]\n [-28486386.32601916]\n [-53950714.81449774]\n [-14132697.55808436]\n [-10576564.45034892]\n [-37975542.13255627]\n [-14559602.19869495]\n [ -5188681.79771511]\n [ -9960099.22618566]\n [-13016690.70889715]\n [-10379163.03159752]\n [ -5526439.71216349]\n [ -9513257.93590328]\n [ -7999414.28884307]\n [-15070674.7596584 ]\n [-12970686.61485531]\n [-21399594.74772953]\n [-13211362.61683335]\n [ -9685086.38103588]\n [-10917099.60154599]\n [-13531744.29365619]\n [ -5812980.16142121]\n [-27480401.0627045 ]\n [ -8256803.17327394]\n [-14714274.50238937]\n [ -8747895.50403229]\n [-25099864.88928807]\n [-14020232.72801471]\n [-34213201.47733276]\n [ -6251018.9383999 ]\n [-27805583.74280867]\n [-28461845.70527195]\n [-25310444.50028571]\n [-19922210.30194341]\n [-10400967.58105183]\n [-12539369.45996964]\n [-38497581.05906311]\n [ -9801025.30195983]\n [ -7196292.6902391 ]\n [-14950321.08260697]\n [ -8738846.38450493]\n [ -9545079.81381261]\n [-50447853.15662791]\n [-27193796.10355327]\n [-35907173.60606485]\n [-10266065.81642036]\n [-11968880.81059328]\n [-34968793.7495959 ]\n [ -9059643.12646805]\n [-13418859.74320111]\n [-15302841.40127405]\n [-10398965.63979232]\n [ -8686851.53698546]\n [-20042319.32837439]]\n"
    }
   ],
   "source": [
    "X_ = np.concatenate([np.ones((X_test.shape[0], 1)), X_test], axis=1)\n",
    "y_pred = lr.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-31aab7f2cb8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondadbe9a6d1582d412dbd0b01bd072c712f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}